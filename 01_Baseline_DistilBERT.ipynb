{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import random\n",
    "import shap\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a helper function to map stars to sentiment\n",
    "def map_stars_to_sentiment(stars):\n",
    "    \n",
    "    if stars >= 4:\n",
    "        return \"POSITIVE\"\n",
    "    else:\n",
    "        return \"NEGATIVE\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 1. Setup the model and tokenizer\n",
    "# --------------------------\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Load tokenizer and model, and move model to GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(\"cuda\")\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Create the Hugging Face sentiment analysis pipeline.\n",
    "# The pipeline will apply truncation automatically.\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0  # Use GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2. Define a prediction function for SHAP\n",
    "# --------------------------\n",
    "def model_predict(texts):\n",
    "    \"\"\"\n",
    "    Takes a list of texts, tokenizes them with padding and truncation,\n",
    "    moves inputs to GPU, and returns logits as numpy arrays.\n",
    "    \"\"\"\n",
    "    # Ensure all inputs are strings\n",
    "    texts = [str(t) for t in texts]\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.logits.detach().cpu().numpy()\n",
    "\n",
    "# Create a text masker for SHAP (to correctly mask tokens)\n",
    "masker = shap.maskers.Text(tokenizer)\n",
    "\n",
    "# Initialize the SHAP explainer with our custom prediction function and masker.\n",
    "explainer = shap.Explainer(model_predict, masker, output_names=[\"Negative\", \"Positive\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# 3. Process Your Reviews from CSV in Batches and Save Sentiment Predictions\n",
    "# --------------------------\n",
    "# file_path = \"reviews_sample.csv\"  # Your CSV file with a \"review_text\" column\n",
    "file_path = \"pre_covid_reviews.csv\"\n",
    "chunk_size = 2000  # Adjust based on your system's memory\n",
    "batch_size = 64\n",
    "counter = 0\n",
    "\n",
    "\n",
    "all_prediction_dfs = []\n",
    "all_shap_explanations = []\n",
    "\n",
    "# Process the CSV file in chunks\n",
    "for chunk in tqdm(pd.read_csv(file_path, chunksize=chunk_size), desc=\"Processing CSV chunks\"):\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"Processed {counter} chunks\")\n",
    "    # Filter out missing review texts and ensure they are strings\n",
    "    texts = [str(t) for t in chunk[\"text\"].dropna().tolist()]\n",
    "    \n",
    "    # Run sentiment analysis in batches; pipeline applies truncation automatically.\n",
    "    predictions = sentiment_pipeline(texts, batch_size=batch_size, truncation=True)\n",
    "    \n",
    "    # Append prediction results to the chunk dataframe:\n",
    "    # Create new columns for the predicted label and score.\n",
    "    chunk = chunk.dropna(subset=[\"text\"]).copy()\n",
    "    chunk[\"prediction\"] = [p[\"label\"] for p in predictions]\n",
    "    chunk[\"score\"] = [p[\"score\"] for p in predictions]\n",
    "    \n",
    "    all_prediction_dfs.append(chunk)\n",
    "    \n",
    "    # For SHAP explanations, select a small random sample from the current chunk.\n",
    "    if texts:\n",
    "        sample_texts = random.sample(texts, k=min(10, len(texts)))\n",
    "        shap_expl = explainer(sample_texts)\n",
    "        all_shap_explanations.append(shap_expl)\n",
    "\n",
    "# Combine all chunk prediction dataframes into one\n",
    "predictions_df = pd.concat(all_prediction_dfs, ignore_index=True)\n",
    "\n",
    "# Apply the mapping to get \"true\" sentiment levels (if stars >= 4)\n",
    "predictions_df[\"true_sentiment\"] = predictions_df[\"stars\"].apply(map_stars_to_sentiment)\n",
    "\n",
    "# Create a numeric sentiment value:\n",
    "# For Positive predictions, sentiment_value = score; for Negative, sentiment_value = -score.\n",
    "predictions_df['sentiment_value'] = predictions_df.apply(\n",
    "    lambda row: row['score'] if row['prediction'] == \"POSITIVE\" else -row['score'], axis=1\n",
    ")\n",
    "\n",
    "predictions_df.to_csv(\"sentiment_predictions.csv\", index=False)\n",
    "print(\"Sentiment predictions saved to sentiment_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# To save the list to a file:\n",
    "with open(\"all_shap_explanations.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_shap_explanations, f)\n",
    "print(\"SHAP explanations saved to all_shap_explanations.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 4. Aggregate SHAP Values to Extract Top Positive and Top Negative Tokens\n",
    "# --------------------------\n",
    "# We will aggregate a \"net contribution\" per token for each sample.\n",
    "# For binary classification, each token gets an array like [neg_value, pos_value].\n",
    "# We'll compute net_contrib = pos_value - neg_value.\n",
    "positive_contributions = defaultdict(list)\n",
    "negative_contributions = defaultdict(list)\n",
    "\n",
    "for explanation in all_shap_explanations:\n",
    "    # explanation.data is a list (per sample) of token lists.\n",
    "    # explanation.values is an array (per sample) of SHAP value arrays.\n",
    "    for sample_tokens, sample_values in zip(explanation.data, explanation.values):\n",
    "\n",
    "        for token, shap_val in zip(sample_tokens, sample_values):\n",
    "            # If shap_val is an array with two values (for negative and positive)\n",
    "            # compute the net contribution.\n",
    "            net_contrib = shap_val[1] - shap_val[0]\n",
    "            if net_contrib >= 0:\n",
    "                positive_contributions[token].append(net_contrib)\n",
    "            else:\n",
    "                negative_contributions[token].append(net_contrib)\n",
    "\n",
    "# Compute average net contribution per token\n",
    "avg_positive = {token: np.mean(vals) for token, vals in positive_contributions.items() if vals}\n",
    "avg_negative = {token: np.mean(vals) for token, vals in negative_contributions.items() if vals}\n",
    "\n",
    "\n",
    "sorted_positive = sorted(avg_positive.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_negative = sorted(avg_negative.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "pd.DataFrame(sorted_positive, columns=[\"token\", \"avg_net_shap\"]).to_csv(\"top_positive_terms.csv\", index=False)\n",
    "pd.DataFrame(sorted_negative, columns=[\"token\", \"avg_net_shap\"]).to_csv(\"top_negative_terms.csv\", index=False)\n",
    "\n",
    "print(\"Top positive terms saved to top_positive_terms.csv\")\n",
    "print(\"Top negative terms saved to top_negative_terms.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df = pd.read_csv(\"./pre_covid/sentiment_predictions.csv\")\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique true sentiment labels:\", predictions_df[\"true_sentiment\"].unique())\n",
    "print(\"Unique true sentiment labels:\", predictions_df[\"prediction\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy {accuracy_score(predictions_df['true_sentiment'], predictions_df['prediction'])}\")\n",
    "\n",
    "cm = confusion_matrix(predictions_df[\"true_sentiment\"], predictions_df[\"prediction\"], labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "cm_df = pd.DataFrame(cm, index=[\"NEGATIVE\", \"POSITIVE\"], columns=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Pre-Covid Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Pre-Covid Classification Report\")\n",
    "print(classification_report(predictions_df[\"true_sentiment\"], predictions_df[\"prediction\"], labels=[\"NEGATIVE\", \"POSITIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"./pre_covid/all_shap_explanations.pkl\", \"rb\") as f:\n",
    "#     all_shap_explanations = pickle.load(f)\n",
    "# print(\"SHAP explanations loaded from all_shap_explanations.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "positive_contributions = defaultdict(list)\n",
    "negative_contributions = defaultdict(list)\n",
    "\n",
    "# Loop over each SHAP Explanation object (each may contain several samples)\n",
    "for explanation in all_shap_explanations:\n",
    "    # explanation.data: list of lists (tokens per sample)\n",
    "    # explanation.values: numpy array with shape (n_samples, n_tokens, n_classes)\n",
    "    for sample_tokens, sample_values in zip(explanation.data, explanation.values):\n",
    "        # For a two-class model, assume index 1 corresponds to positive and index 0 to negative.\n",
    "        for token, token_values in zip(sample_tokens, sample_values):\n",
    "            positive_contributions[token].append(token_values[1])\n",
    "            negative_contributions[token].append(token_values[0])\n",
    "\n",
    "# Compute the average contribution per token for positive and negative\n",
    "avg_positive = {token: np.mean(vals) for token, vals in positive_contributions.items()}\n",
    "avg_negative = {token: np.mean(vals) for token, vals in negative_contributions.items()}\n",
    "\n",
    "# Compute net contribution per token: (average positive contribution) minus (average negative contribution)\n",
    "net_contributions = {token: avg_positive.get(token, 0) - avg_negative.get(token, 0)\n",
    "                     for token in set(avg_positive) | set(avg_negative)}\n",
    "\n",
    "sorted_net_positive = sorted(net_contributions.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_net_negative = sorted(net_contributions.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"Top tokens driving positive predictions (net contribution):\")\n",
    "for token, net in sorted_net_positive[:20]:\n",
    "    print(f\"{token}: {net:.4f}\")\n",
    "\n",
    "print(\"\\nTop tokens driving negative predictions (net contribution):\")\n",
    "for token, net in sorted_net_negative[:20]:\n",
    "    print(f\"{token}: {net:.4f}\")\n",
    "\n",
    "    \n",
    "if sorted_net_positive:\n",
    "    pos_tokens, pos_scores = zip(*sorted_net_positive[:20])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(pos_tokens, pos_scores)\n",
    "    plt.title(\"Top Tokens Driving Positive Predictions (Net Contribution) [Pre-Covid]\")\n",
    "    plt.xlabel(\"Token\")\n",
    "    plt.ylabel(\"Net SHAP Value\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "if sorted_net_negative:\n",
    "    neg_tokens, neg_scores = zip(*sorted_net_negative[:20])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(neg_tokens, neg_scores)\n",
    "    plt.title(\"Top Tokens Driving Negative Predictions (Net Contribution) [Pre-Covid]\")\n",
    "    plt.xlabel(\"Token\")\n",
    "    plt.ylabel(\"Net SHAP Value\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Box Plot: Distribution of Sentiment Values per Star Rating ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"stars\", y=\"sentiment_value\", data=predictions_df)\n",
    "plt.title(\"Distribution of Sentiment Values by Star Rating\")\n",
    "plt.xlabel(\"Stars\")\n",
    "plt.ylabel(\"Sentiment Value (Positive = Higher, Negative = Lower)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Line Plot: Average Sentiment Value per Star Rating ---\n",
    "avg_sentiment = predictions_df.groupby(\"stars\")[\"sentiment_value\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=\"stars\", y=\"sentiment_value\", data=avg_sentiment, marker=\"o\")\n",
    "plt.title(\"Average Sentiment Value by Star Rating\")\n",
    "plt.xlabel(\"Stars\")\n",
    "plt.ylabel(\"Average Sentiment Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = predictions_df[predictions_df[\"prediction\"].isin([\"POSITIVE\", \"NEGATIVE\"])]\n",
    "\n",
    "# --- Box Plot: Distribution of Star Ratings by Sentiment ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"prediction\", y=\"stars\", data=binary_df)\n",
    "plt.title(\"Star Rating Distribution by Sentiment Prediction [Pre-Covid]\")\n",
    "plt.xlabel(\"Sentiment Prediction\")\n",
    "plt.ylabel(\"Star Rating\")\n",
    "plt.show()\n",
    "\n",
    "# --- Bar Plot: Average Star Rating for Each Sentiment ---\n",
    "avg_stars = binary_df.groupby(\"prediction\")[\"stars\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"prediction\", y=\"stars\", data=avg_stars)\n",
    "plt.title(\"Average Star Rating for Positive vs Negative Reviews\")\n",
    "plt.xlabel(\"Sentiment Prediction\")\n",
    "plt.ylabel(\"Average Star Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with regression fit for each sentiment label\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(x=\"stars\", y=\"sentiment_value\", hue=\"prediction\", data=binary_df,\n",
    "           markers=[\"o\", \"x\"], aspect=1.5, ci=None)\n",
    "plt.title(\"Relationship Between Star Rating and Sentiment Value\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Sentiment Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x=\"stars\", y=\"sentiment_value\", hue=\"prediction\", data=binary_df, split=True)\n",
    "plt.title(\"Distribution of Sentiment Values by Star Rating\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Sentiment Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"stars\", y=\"sentiment_value\", data=binary_df, hue=\"prediction\")\n",
    "plt.title(\"Box Plot of Sentiment Value by Star Rating and Sentiment\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Sentiment Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate # reviews for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_covid = pd.read_csv(\"./pre_covid/sentiment_predictions.csv\")\n",
    "post_covid = pd.read_csv(\"./post_covid/sentiment_predictions.csv\")\n",
    "\n",
    "print(pre_covid.shape)\n",
    "print(post_covid.shape)\n",
    "post_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_businesses = pre_covid['business_id'].value_counts()\n",
    "post_businesses = post_covid['business_id'].value_counts()\n",
    "print(len(pre_businesses))\n",
    "print(len(post_businesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_covid['is_positive'] = pre_covid['prediction'] == 'POSITIVE'\n",
    "pre_covid['is_negative'] = pre_covid['prediction'] == 'NEGATIVE'\n",
    "pre_grouped = pre_covid.groupby(\"business_id\").sum()\n",
    "\n",
    "post_covid['is_positive'] = post_covid['prediction'] == 'POSITIVE'\n",
    "post_covid['is_negative'] = post_covid['prediction'] == 'NEGATIVE'\n",
    "post_grouped = post_covid.groupby(\"business_id\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_covid_agg = pre_grouped[['is_positive', 'is_negative']].rename(columns={'is_positive': 'pre_cov_num_pos', 'is_negative':'pre_cov_num_neg'})\n",
    "post_covid_agg = post_grouped[['is_positive', 'is_negative']].rename(columns={'is_positive': 'post_cov_num_pos', 'is_negative':'post_cov_num_neg'})\n",
    "print(pre_covid_agg.shape, post_covid_agg.shape)\n",
    "pre_covid_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = pre_covid_agg.merge(post_covid_agg, on='business_id', how='outer').fillna(0)\n",
    "print(merged.shape)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged['total_pos_reviews'] = merged['pre_cov_num_pos'] + merged['post_cov_num_pos']\n",
    "merged['total_neg_reviews'] = merged['pre_cov_num_neg'] + merged['post_cov_num_neg']\n",
    "merged['total_num_reviews'] = merged['total_pos_reviews'] + merged['total_neg_reviews']\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv(\"business_review_counts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
